{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agpo-ilr-uni-bonn/PromotionskollegModule6800_2024/blob/master/6800_Day2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71QCGinKTAAf"
      },
      "source": [
        "# Day 2: Code used during lecture and lab assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBjm-4D-Tg-L"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "- The notebook combines 'code used during lecture' with the 'Day 2 lab' assignment (see further down)\n",
        "- The lab assignment can be done largely by copying/paste/modification of the code used during the lecture\n",
        "- Please add answers/discussion/comments to the notebook as comments or text box. Do not create another file in addition.\n",
        "- When you are done with your assignment, save the notebook in drive and add your last name to the name of the file.\n",
        "- To hand in the final notebook follow the instructions provided by email\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sINvJ4ugbKhz"
      },
      "source": [
        "# **Code used during lecture**\n",
        "## Part One: Tree based methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xn9LO_jCSar8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn import tree\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHtbUP2Uf_pO"
      },
      "outputs": [],
      "source": [
        "# Set the numpy random seed\n",
        "np.random.seed(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWJ6IasttlnW"
      },
      "outputs": [],
      "source": [
        "# run this cell only once if you don't have wget installed\n",
        "# its assumed you are using windows and have python installed\n",
        "# only needed if you are running the notebook locally\n",
        "# %pip install wget\n",
        "#if not os.path.isfile('brazil_all_data_v2.gz'):\n",
        "#    !python -m wget  https://ilr-ml.s3.eu-central-1.amazonaws.com/brazil_all_data_v2.gz\n",
        "# Download data only once and make sure it is in the same folder as the notebook\n",
        "\n",
        "# check if brazil_all_data_v2.gz is available in the current folder and if not, download it\n",
        "\n",
        "if not os.path.isfile('brazil_all_data_v2.gz'):\n",
        "    !wget  https://ilr-ml.s3.eu-central-1.amazonaws.com/brazil_all_data_v2.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8QMuJ64tnh9"
      },
      "outputs": [],
      "source": [
        "# Load data with pandas into a dataframe\n",
        "df = pd.read_parquet('brazil_all_data_v2.gz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DN3evVUDoiVx"
      },
      "outputs": [],
      "source": [
        "# Define binary variable for deforestration in 2018\n",
        "df['D_defor_2018'] = df['defor_2018']>0\n",
        "Y_all = df['D_defor_2018']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2ZGZoInoHAV"
      },
      "outputs": [],
      "source": [
        "# Define a list of features names (explantory variables)\n",
        "lstX = [\n",
        "  'wdpa_2017',\n",
        "  'population_2015',\n",
        "  'chirps_2017',\n",
        "  'defor_2017',\n",
        "  'maize',\n",
        "  'soy',\n",
        "  'sugarcane',\n",
        "  'perc_treecover',\n",
        "  'perm_water',\n",
        "  'travel_min',\n",
        "  'cropland',\n",
        "  'mean_elev',\n",
        "  'sd_elev',\n",
        "  'near_road',\n",
        "  'defor_2017_lag_1st_order',\n",
        "  'wdpa_2017_lag_1st_order',\n",
        "  'chirps_2017_lag_1st_order',\n",
        "  'population_2015_lag_1st_order',\n",
        "  'maize_lag_1st_order',\n",
        "  'soy_lag_1st_order',\n",
        "  'sugarcane_lag_1st_order',\n",
        "  'perc_treecover_lag_1st_order',\n",
        "  'perm_water_lag_1st_order',\n",
        "  'travel_min_lag_1st_order',\n",
        "  'cropland_lag_1st_order',\n",
        "  'mean_elev_lag_1st_order',\n",
        "  'sd_elev_lag_1st_order',\n",
        "  'near_road_lag_1st_order',\n",
        " ]\n",
        "\n",
        "# Get the explanatory Variables\n",
        "X_all =  df.loc[:,lstX]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZ5TrMhZ2pxs"
      },
      "outputs": [],
      "source": [
        "# Split the data into train and test data using sklearn train_test_split object\n",
        "#   (see: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
        "\n",
        "#   Note: This randomly split the data in 80% train and 20% test data\n",
        "X_train_raw, X_test_raw, Y_train, Y_test = train_test_split(X_all, Y_all, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9ijNiMD2nH9"
      },
      "outputs": [],
      "source": [
        "# Scale data to 0-1 range using sklearn MinMaxScalar object\n",
        "# (see: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)\n",
        "scaler = MinMaxScaler()\n",
        "# Use only the train data to fit the MinMaxScalar\n",
        "scaler.fit(X_train_raw)\n",
        "\n",
        "# Apply the MinMax transformation to the train and test data\n",
        "X_train = scaler.transform(X_train_raw)\n",
        "X_test = scaler.transform(X_test_raw)\n",
        "# Note the depended variable does not need to be scaled as it is a binary variable anyway"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRd3KIDXp152"
      },
      "source": [
        "Run logit on deforestation binary variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSjHfg6PmxDA"
      },
      "outputs": [],
      "source": [
        "# Fit a logistic regression model using sklearn\n",
        "# (see: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
        "\n",
        "# Create the model object\n",
        "modelLg = LogisticRegression(random_state=0,penalty=None,fit_intercept=True,max_iter=1000)\n",
        "# Fit the model using the training data\n",
        "modelLg.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOuCMR7V-_Ta"
      },
      "outputs": [],
      "source": [
        "# Define a function that prints the model statistics.\n",
        "# We will use the function below to always get the same model stats for each of\n",
        "# the models the we will estimate below.\n",
        "def printOutput(mod,X_train,Y_train,X_test,Y_test):\n",
        "  # view results\n",
        "  print('Score in train', mod.score(X_train, Y_train))\n",
        "  print('Score in test', mod.score(X_test, Y_test))\n",
        "\n",
        "  Y_test_had_Tree = mod.predict(X_test)\n",
        "\n",
        "  print('\\nConfusion Matrix')\n",
        "  print(pd.DataFrame(confusion_matrix(Y_test, Y_test_had_Tree),\n",
        "            index=pd.MultiIndex.from_arrays([['actual','actual'], ['False','True']]),\n",
        "            columns=pd.MultiIndex.from_arrays([['predicted','predicted'], ['False','True']])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toJ0q4YvoEs9"
      },
      "outputs": [],
      "source": [
        "# Use the function to print the model statistics for our logit model\n",
        "printOutput(modelLg,X_train,Y_train,X_test,Y_test)\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "\n",
        "# Get the predicted probabiltities\n",
        "Y_score = modelLg.decision_function(X_test)\n",
        "\n",
        "# Get true positive and false positive rate\n",
        "# See: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html\n",
        "fpr_Lg, tpr_Lg, _ = roc_curve(Y_test, Y_score)\n",
        "\n",
        "# Get the Area under the cureve (AUC)\n",
        "# See: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html\n",
        "roc_auc_Lg = auc(fpr_Lg, tpr_Lg)\n",
        "\n",
        "print('\\nROC AUC', roc_auc_Lg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dR7Zu0K_6PKO"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr_Lg, tpr_Lg, color='darkorange',\n",
        "         lw=lw, label='Logistic ROC curve (area = %0.2f' % roc_auc_Lg)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWCB8SaR1Qlm"
      },
      "source": [
        "Now run a decision tree using the same specification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9C2g9xH8qFig"
      },
      "outputs": [],
      "source": [
        "# Fit a decision tree using sklearn\n",
        "# (see https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
        "\n",
        "# Define a model object\n",
        "modelTree = tree.DecisionTreeClassifier()\n",
        "# Fit the model\n",
        "modelTree = modelTree.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X45zdwZblFDK"
      },
      "outputs": [],
      "source": [
        "# Use the function to print the model statistics for our tree model\n",
        "printOutput(modelTree,X_train,Y_train,X_test,Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUu8fjY-2P6m"
      },
      "source": [
        "Run the same model using  a random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HOeVa-8z2KNL"
      },
      "outputs": [],
      "source": [
        "# run a random forest using sklearn and default hyperparameters (note, this will take a few minutes)\n",
        "# (see https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create model object\n",
        "# Note: We reduce the number of estimators here to speed-up runtime,\n",
        "#       default value for n_estimators is 100\n",
        "modelForest = RandomForestClassifier(n_estimators=20)\n",
        "# Fit model\n",
        "modelForest = modelForest.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OvZPmhHH96Yv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352f8db1-7857-44be-e67c-a64b08228cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score in train 0.995879010962631\n",
            "Score in test 0.8298991758021925\n",
            "\n",
            "Confusion Matrix\n",
            "             predicted      \n",
            "                 False  True\n",
            "actual False     35565  2374\n",
            "       True       6129  5920\n"
          ]
        }
      ],
      "source": [
        "# Print model output stats\n",
        "printOutput(modelForest,X_train,Y_train,X_test,Y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyMYFqribubG"
      },
      "outputs": [],
      "source": [
        "# ====================\n",
        "# Discuss in the group\n",
        "# ====================\n",
        "# What do you conclude from the model outcome. Is this a\n",
        "# useful model. Compare the results to the logit outcomes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lqaLHLVdvKl"
      },
      "outputs": [],
      "source": [
        "# Plot ROC curve\n",
        "# Get the predicted probabiltities\n",
        "Y_scoreRF = modelForest.predict_proba(X_test)[:,1]\n",
        "\n",
        "# Get true positive and false positive rate\n",
        "fpr_RF, tpr_RF, _ = roc_curve(Y_test, Y_scoreRF)\n",
        "\n",
        "# Get the Area under the cureve (AUC)\n",
        "roc_auc_RF = auc(fpr_RF, tpr_RF)\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr_RF, tpr_RF,\n",
        "         lw=lw, label='RF ROC curve (area = %0.2f' % roc_auc_RF)\n",
        "plt.plot(fpr_Lg, tpr_Lg,\n",
        "         lw=lw, label='Logistic ROC curve (area = %0.2f' % roc_auc_Lg)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh5EZajJsA8N"
      },
      "source": [
        "Visualizing the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeXTB7BZsgc3"
      },
      "outputs": [],
      "source": [
        "# Generate a feature importance graph for the forest\n",
        "# Adjusted based on  https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
        "\n",
        "importances = modelForest.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in modelForest.estimators_],\n",
        "             axis=0)\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Print the feature ranking\n",
        "print(\"Feature ranking:\")\n",
        "\n",
        "\n",
        "for f in range(X_train.shape[1]):\n",
        "    print(\"%d. %s (%f)\" % (f + 1, lstX[f], importances[indices[f]]))\n",
        "\n",
        "# Plot the impurity-based feature importances of the forest\n",
        "plt.figure()\n",
        "plt.title(\"Feature importances\")\n",
        "plt.bar(range(X_train.shape[1]), importances[indices],\n",
        "        color=\"r\", yerr=std[indices], align=\"center\")\n",
        "# plt.xticks(range(X_train.shape[1]), indices)\n",
        "plt.xlim([-1, X_train.shape[1]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part Two: SHAP values"
      ],
      "metadata": {
        "id": "_w9MkmMOyuz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First install the SHAP libary\n",
        "!pip install -q shap"
      ],
      "metadata": {
        "id": "ZbL3FeclybXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpX118QxyA16"
      },
      "outputs": [],
      "source": [
        "# Import the shape libary\n",
        "import shap\n",
        "# Load JS visualization code to notebook\n",
        "shap.initjs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_o11ioqyA2T"
      },
      "outputs": [],
      "source": [
        "# Create a dataframe for our train data that includes the variable names\n",
        "df_X_train = pd.DataFrame(X_train,columns=lstX)\n",
        "\n",
        "# Explain the model's predictions using SHAP\n",
        "# (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)\n",
        "explainer = shap.TreeExplainer(modelForest)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_X_train_subsample = shap.sample(df_X_train, 100)"
      ],
      "metadata": {
        "id": "Jwr41-8YCgiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the shape values using the TreeExplainer object\n",
        "shap_values = explainer.shap_values(df_X_train_subsample)"
      ],
      "metadata": {
        "id": "TNrMgBRCCTAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predicted probabilities to compare shape values\n",
        "# Y_train_proba = modelTree.predict_proba(df_X_train_subsample)\n",
        "Y_train_proba = modelForest.predict_proba(df_X_train_subsample)"
      ],
      "metadata": {
        "id": "t6sB8caRyA2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect shape of SHAP values\n",
        "shap_values.shape\n"
      ],
      "metadata": {
        "id": "6LezYRKTyA2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(shap_values[lstX.index('defor_2017'),:,1]);"
      ],
      "metadata": {
        "id": "JjqT39qeyA2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcVLw50uyA2Y"
      },
      "outputs": [],
      "source": [
        "# visualize the first prediction's explanation\n",
        "# shap.force_plot(explainer.expected_value, shap_values[0,:], df_X_train.iloc[0,:])\n",
        "iobs = 0\n",
        "# If you have a javascript error use matplotlib=True to avoid Javascript\n",
        "shap.force_plot(explainer.expected_value[0], shap_values[iobs,:,1],\n",
        "                np.round(df_X_train_subsample.iloc[iobs,:],4),matplotlib=True,\n",
        "                contribution_threshold=0.1)\n",
        "# Note: This might look different than the version the slides because another random seed\n",
        "#       was used to create the plots in the slides"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore shape values manually\n",
        "shap_iobs = explainer.expected_value + shap_values[iobs,:].sum()\n",
        "print(f'SHAP value of obs {iobs}:',shap_iobs)\n",
        "print('SHAP value for base:', explainer.expected_value)\n",
        "\n",
        "# SHAP value are in log-odds, transform to probability\n",
        "print('Expected Prob:',np.exp(explainer.expected_value) / (1 + np.exp(explainer.expected_value)))\n",
        "print(f'Prob of obs {iobs}:',np.exp(shap_iobs) / (1 + np.exp(shap_iobs)))\n",
        "\n",
        "# compare to predicted proability\n",
        "print(f'Proba of obs {iobs}:', Y_train_proba[iobs][1])"
      ],
      "metadata": {
        "id": "XZKmvG_syA2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoA_xEY6rLjw"
      },
      "source": [
        "# **Lab**\n",
        "## Part One: Tree based methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faiHfDS04JDD"
      },
      "source": [
        "The lab today will have you predict deforestation using both a random forest and XGboost models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfVYG7QSay2e"
      },
      "outputs": [],
      "source": [
        "# In the lecture part we have run a Random Forest that heavily\n",
        "# overfitted the training data. Adjust a hyperparamter\n",
        "# and see if you can train a model that does not overfit.\n",
        "\n",
        "# Hint: Vary the parameter max_depth or min_samples_split\n",
        "\n",
        "# Sklearn documentation on RF:\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict_proba\n",
        "\n",
        "# ==============\n",
        "# Your code here\n",
        "# ==============\n",
        "modelForest = ...\n",
        "\n",
        "# Fit model\n",
        "...\n",
        "\n",
        "#  Print model stats output\n",
        "printOutput(...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_l6voaZ5SasI"
      },
      "outputs": [],
      "source": [
        "# Now run an XGBoost model for the same task\n",
        "import xgboost as xgb\n",
        "\n",
        "# Hint: 1) Look at one of the tutorial on XGB on how to specify and run the model\n",
        "#          (e.g. https://hackernoon.com/want-a-complete-guide-for-xgboost-model-in-python-using-scikit-learn-sc11f31bq)\n",
        "#       2) You do not need to adjust hypterparamter here. The default paramters\n",
        "#          should be fine here.\n",
        "\n",
        "# ==============\n",
        "# Your code here\n",
        "# ==============\n",
        "# Specify model\n",
        "model_xgb = ...\n",
        "\n",
        "\n",
        "# Fit model to data\n",
        "model_xgb ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_0NfwuZAQF1"
      },
      "outputs": [],
      "source": [
        "# Print the model stats of you XGB model using the function from above\n",
        "# ==============\n",
        "# Your code here\n",
        "# ==============\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uv_0pQBtApns"
      },
      "outputs": [],
      "source": [
        "# Compare to the outcome of the other model\n",
        "# (not need to change anything here)\n",
        "print('\\n--- Logistic')\n",
        "printOutput(modelLg,X_train,Y_train,X_test,Y_test)\n",
        "\n",
        "print('\\n--- Tree')\n",
        "printOutput(modelTree,X_train,Y_train,X_test,Y_test)\n",
        "\n",
        "print('\\n--- Forest')\n",
        "printOutput(modelForest,X_train,Y_train,X_test,Y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RwF-b5NcE2Z"
      },
      "outputs": [],
      "source": [
        "# Write a couple of sentences on what you see in your models, which you\n",
        "# believe are performing better and why\n",
        "# ================\n",
        "# Your answer here\n",
        "# ================\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wbPaM6uewwX"
      },
      "outputs": [],
      "source": [
        "# Plot an ROC corve for the Logit, Random Forest and XGB model\n",
        "\n",
        "# Hint: Check what we have done above...\n",
        "# ==============\n",
        "# Your code here\n",
        "# ==============\n",
        "# Get the predicted probabiltities\n",
        "Y_scoreXG = ...\n",
        "\n",
        "# Get true positive and false positive rate\n",
        "fpr_XG, tpr_XG, _ = ...\n",
        "\n",
        "# Get the Area under the cureve (AUC)\n",
        "roc_auc_XG = ...\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpXpt0TUhOWr"
      },
      "outputs": [],
      "source": [
        "# Plot the figure (not need to change anything here)\n",
        "plt.figure()\n",
        "lw = 2\n",
        "\n",
        "plt.plot(fpr_XG, tpr_XG,\n",
        "         lw=lw, label='XG ROC curve (area = %0.2f' % roc_auc_XG)\n",
        "\n",
        "plt.plot(fpr_Lg, tpr_Lg,\n",
        "         lw=lw, label='Logistic ROC curve (area = %0.2f' % roc_auc_Lg)\n",
        "\n",
        "plt.plot(fpr_RF, tpr_RF,\n",
        "         lw=lw, label='RF ROC curve (area = %0.2f' % roc_auc_RF)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWmorRE8cwUE"
      },
      "outputs": [],
      "source": [
        "# In one or two sentences, discuss what the ROC curves are telling you\n",
        "# ================\n",
        "# Your answer here\n",
        "# ================\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw2LzA78eCjt"
      },
      "source": [
        "### Optional Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVItUaaw4T4p"
      },
      "source": [
        "(Optional) Generate your model's prediction errors and explore them - comparing different subsets of your data (e.g. protected areas vs others)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlZwcBqV4EzK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch0YN9iV-4b-"
      },
      "source": [
        "## Lab Part Two: SHAP Values\n",
        "The second part focus on SHAP values. First we show you how to plot SHAP values for the XG Boost model, which you have already seen in the lecutre. Then you  should create SHAP values for the logit model and explore how SHAP value would look like in a well known linear model.\n",
        "\n",
        "More on SHAP values:\n",
        "\n",
        "https://github.com/slundberg/shap\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First run the code for SHAP values from the Lecture, then continue with this part**"
      ],
      "metadata": {
        "id": "w_qM4bm_4Lcr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHA3Lh-ZBqmp"
      },
      "outputs": [],
      "source": [
        "# ====================\n",
        "# Discuss in the group\n",
        "# ====================\n",
        "# How do you interpret this plot?\n",
        "# When might you want to use a plot like this?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYxvmFWNBriW"
      },
      "outputs": [],
      "source": [
        "# summarize the effects of all the features\n",
        "shap.summary_plot(shap_values[:,:,1], df_X_train_subsample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhTi4m7YB0K6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ====================\n",
        "# Discuss in the group\n",
        "# ====================\n",
        "# How do you interpret this plot?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To rrproduce the plot in the lecture use a larger subsample size\n",
        "# Note, that computation takes longer the larger the subsample size\n",
        "df_X_train_subsample = shap.sample(df_X_train, 1000)\n",
        "shap_values = explainer.shap_values(df_X_train_subsample)"
      ],
      "metadata": {
        "id": "eND_tCjI_12f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5QIdtGsB6RB"
      },
      "outputs": [],
      "source": [
        "# create a dependence plot to show the effect of a single feature across the whole dataset\n",
        "shap.dependence_plot(\"defor_2017\", shap_values[:,:,1], df_X_train_subsample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDA1xZNEB7MC"
      },
      "outputs": [],
      "source": [
        "# ====================\n",
        "# Discuss in the group\n",
        "# ====================\n",
        "# How do you interpret this plot?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-olD0n8B_wf"
      },
      "outputs": [],
      "source": [
        "# ====================\n",
        "# Discuss in the group\n",
        "# ====================\n",
        "# Before you start creating the plots, discuss in the group what kind of\n",
        "# results you expect for the linear model. Specifically, think about how the\n",
        "# last plot (the dependence_plot) would look in this case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E25A2Sg_CEDq"
      },
      "outputs": [],
      "source": [
        "# Here we use the shap.LinearExplainer() function instead of the\n",
        "# shap.TreeExplainer(...) we used above\n",
        "\n",
        "# You can have a look here for a reference:\n",
        "# https://slundberg.github.io/shap/notebooks/linear_explainer/Sentiment%20Analysis%20with%20Logistic%20Regression.html\n",
        "\n",
        "# ==============\n",
        "# Your code here\n",
        "# ==============\n",
        "explainer = ...\n",
        "\n",
        "shap_values = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CDCjFiICHL0"
      },
      "outputs": [],
      "source": [
        "# Now create a dependence plot to show the effect of a single feature\n",
        "# across the whole dataset, as was done above but now for the logit model\n",
        "\n",
        "# ==============\n",
        "# Your code here\n",
        "# ==============\n",
        " ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bej8MxAfCUa3"
      },
      "outputs": [],
      "source": [
        "# ====================\n",
        "# Discuss in the group\n",
        "# ====================\n",
        "\n",
        "\n",
        "# 1) Does this look like to what you expected?\n",
        "\n",
        "# 2) How does this compare to the plot for the XGB model. What can you conclude?\n",
        "\n",
        "# Note: Below you find the usual regression output for logit model again. This\n",
        "#       might be interesting as a reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tp2EXrOJCWu1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Have a look at the SHAP summary plot\n",
        "shap.summary_plot(shap_values, df_X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsu6_a-sCctM"
      },
      "source": [
        "## **For your reference**\n",
        "\n",
        "Lets create our usual regression output for the logit model as a reference\n",
        "\n",
        "This used the same code from the lab intro session.\n",
        "\n",
        "(Not need to change/do anything here)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaC5K-uQCZV0"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import norm\n",
        "# Function to calculate pvalues and standard errors for a scikit-learn logisticRegression\n",
        "# Source: https://stackoverflow.com/questions/25122999/scikit-learn-how-to-check-coefficients-significance\n",
        "def logit_pvalue(model, x):\n",
        "    \"\"\" Calculate z-scores for scikit-learn LogisticRegression.\n",
        "    parameters:\n",
        "        model: fitted sklearn.linear_model.LogisticRegression with intercept and large C\n",
        "        x:     matrix on which the model was fit\n",
        "    This function uses asymtptics for maximum likelihood estimates.\n",
        "    \"\"\"\n",
        "    p = model.predict_proba(x)\n",
        "    n = len(p)\n",
        "    m = len(model.coef_[0]) + 1\n",
        "    # m = len(model.coef_[0])\n",
        "    # coefs = model.coef_[0]\n",
        "    coefs = np.concatenate([model.intercept_, model.coef_[0]])\n",
        "    x_full = np.matrix(np.insert(np.array(x), 0, 1, axis = 1))\n",
        "    ans = np.zeros((m, m))\n",
        "    for i in range(n):\n",
        "        ans = ans + np.dot(np.transpose(x_full[i, :]), x_full[i, :]) * p[i,1] * p[i, 0]\n",
        "    vcov = np.linalg.inv(np.matrix(ans))\n",
        "    se = np.sqrt(np.diag(vcov))\n",
        "    t =  coefs/se\n",
        "    p = (1 - norm.cdf(abs(t))) * 2\n",
        "    return se, p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_UOyyFCCqe0"
      },
      "outputs": [],
      "source": [
        "# Use the previously created function to create a regression output table\n",
        "se, p = logit_pvalue(modelLg, X_train)\n",
        "coefs = np.concatenate([modelLg.intercept_, modelLg.coef_[0]]).T\n",
        "resCoef = pd.DataFrame(coefs,index=['constant']+lstX)\n",
        "resCoef.columns = ['coef']\n",
        "resCoef['se'] = se\n",
        "resCoef['pval'] = p\n",
        "resCoef"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug0JyzwZC1hz"
      },
      "source": [
        "### **Optional Tasks**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0MHR3oxoIB0"
      },
      "outputs": [],
      "source": [
        "# (Optional-1) Explore the Shapley Value Explanations for different sub-sets of the data (e.g. protected areas versus others)\n",
        "#  and in a few sentences, discuss your findings\n",
        "#================\n",
        "\n",
        "#================"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.11 ('ml')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "b2dd1c5c1941d22dfbdf86f16c96d8db5c09a3d6da608d7809bd79814f897e15"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}